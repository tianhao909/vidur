{"clusters": [{"device": "h100", "num_gpus": 16, "gpus_per_node": 4}], "schedulers": [{"scheduler": "vllm"}, {"scheduler": "sarathi", "chunk_size": 256}, {"scheduler": "sarathi", "chunk_size": 512}], "traces": [{"name": "arxiv", "trace_file": "./data/processed_traces/arxiv_summarization_stats_llama2_tokenizer_filtered_v2.csv", "max_seq_len": 4096, "num_requests": 16000, "start_qps": 16}], "batch_sizes": [32], "tp_dimensions": [1], "pp_dimensions": [1], "models": [{"name": "llama-2-7b-hf", "identifier": "meta-llama/Llama-2-7b-hf"}]}