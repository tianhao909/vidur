clusters:
  - device: h100
    num_gpus: 16
    gpus_per_node: 4
  - device: a100
    num_gpus: 16
    gpus_per_node: 4

schedulers:
  - scheduler: vllm
  - scheduler: sarathi
    chunk_size: 256
  - scheduler: sarathi
    chunk_size: 4096

traces:
  - name: chat
    trace_file: "./data/processed_traces/lmsys_chat_1m_conversation_stats_llama2_tokenizer.csv"
    max_seq_len: 4096
    num_requests: 16000
    start_qps: 4
  - name: arxiv
    trace_file: "./data/processed_traces/arxiv_summarization_stats_llama2_tokenizer_filtered_v2.csv"
    max_seq_len: 4096
    num_requests: 16000
    start_qps: 4

batch_sizes: [32, 64]
tp_dimensions: [1, 2]
pp_dimensions: [1, 2]

models:
  - name: phi-2
    identifier: microsoft/phi-2
    exclude_tp_dims: [2, 4, 8]
  - name: llama-2-7b-hf
    identifier: meta-llama/Llama-2-7b-hf
